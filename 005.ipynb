{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import requests\n",
    "import dask.dataframe as dd\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pipe(caption):\n",
    "    return pipe(\"Provide the mood for the description of a piece of music: \" + caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dd.read_csv('DATASET/Captioned/*.csv')\n",
    "df['mood'] = df['captioning'].apply(apply_pipe, meta=('mood', 'int'))\n",
    "df = df.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['pop.00080.wav',\n",
       "        '[0:00-10:00]\\nThis is an R&B/pop music piece. There is a female vocalist singing melodically. The melody is being played by the keyboard while the bass guitar is playing in the background. The rhythm is provided by a simple electronic drum beat. The atmosphere is urban. This piece could be used in the soundtrack of a teenage drama movie that takes place in the big city. \\n \\n[10:00-20:00]\\nThis is an R&B/pop music piece. There is a female vocalist singing melodically in the lead. The melody is being played by the keyboard while the bass guitar is playing in the background. The rhythm is provided by a simple electronic drum beat. The atmosphere is sentimental. This piece could be used in the soundtrack of a romantic comedy movie, especially during the scenes where a character is going through the feeling of heartbreak. \\n \\n[20:00-30:00]\\nThis is an R&B/pop music piece. There is a female vocalist singing melodically in the lead. The melody is being played by the keyboard while the bass guitar is playing in the background. The rhythm consists of an electronic drum beat. The atmosphere is danceable. This piece could be used in the soundtrack of a teenage drama movie, especially during the scenes where a character is hesitating to their crush. \\n \\n',\n",
       "        list([[{'label': 'neutral', 'score': 0.7530854940414429}, {'label': 'approval', 'score': 0.2039482444524765}, {'label': 'realization', 'score': 0.04238647222518921}, {'label': 'admiration', 'score': 0.02436583675444126}, {'label': 'joy', 'score': 0.006202120799571276}, {'label': 'amusement', 'score': 0.005636930000036955}, {'label': 'optimism', 'score': 0.005326977465301752}, {'label': 'love', 'score': 0.0047986977733671665}, {'label': 'sadness', 'score': 0.003258586162701249}, {'label': 'excitement', 'score': 0.0032120905816555023}, {'label': 'disappointment', 'score': 0.0028976071625947952}, {'label': 'annoyance', 'score': 0.0022988785058259964}, {'label': 'confusion', 'score': 0.0022842469625175}, {'label': 'disapproval', 'score': 0.0015879204729571939}, {'label': 'relief', 'score': 0.0015556374564766884}, {'label': 'fear', 'score': 0.0013256131205707788}, {'label': 'caring', 'score': 0.0013234636280685663}, {'label': 'curiosity', 'score': 0.0013047887478023767}, {'label': 'desire', 'score': 0.0012488033389672637}, {'label': 'disgust', 'score': 0.001242642174474895}, {'label': 'pride', 'score': 0.00115870195440948}, {'label': 'surprise', 'score': 0.0010975939221680164}, {'label': 'nervousness', 'score': 0.0007256506360135972}, {'label': 'grief', 'score': 0.000580746156629175}, {'label': 'embarrassment', 'score': 0.0005529372720047832}, {'label': 'gratitude', 'score': 0.0005371130537241697}, {'label': 'anger', 'score': 0.0004057043115608394}, {'label': 'remorse', 'score': 0.00040425636689178646}]])],\n",
       "       ['reggae.00069.wav',\n",
       "        '[0:00-10:00]\\nThis reggae song features a male voice singing the main melody. Other male voices sing backing voices repeating the same melody in between lines. This is accompanied by percussion playing a reggae beat. The bass plays a groovy bassline using runs within the scale. A keyboard plays chords in the background. The mood of this song is happy. This song can be played in a Caribbean themed party. \\n \\n[10:00-20:00]\\nThis reggae song features a male voice singing the main melody. Other male voices sing backing vocals in harmony with the main voice. This is accompanied by percussion playing a simple reggae beat. The bass plays a groovy bassline. A keyboard plays chords in the background. The mood of this song is happy. This song can be played in a Caribbean style movie. \\n \\n[20:00-30:00]\\nThis reggae song features a male voice singing the main melody. Other male voices sing backing voices repeating the same melody in between lines. This is accompanied by percussion playing a simple reggae beat. The bass plays a groovy bassline using runs within the scale. A keyboard plays chords in the background. This song can be played in a Caribbean style movie. \\n \\n',\n",
       "        list([[{'label': 'joy', 'score': 0.5456526279449463}, {'label': 'neutral', 'score': 0.28309154510498047}, {'label': 'approval', 'score': 0.17735816538333893}, {'label': 'excitement', 'score': 0.049842607229948044}, {'label': 'admiration', 'score': 0.03438235819339752}, {'label': 'amusement', 'score': 0.023883415386080742}, {'label': 'love', 'score': 0.013395584188401699}, {'label': 'realization', 'score': 0.01260309386998415}, {'label': 'relief', 'score': 0.010483079589903355}, {'label': 'optimism', 'score': 0.00884504709392786}, {'label': 'caring', 'score': 0.00628404226154089}, {'label': 'pride', 'score': 0.004942558705806732}, {'label': 'annoyance', 'score': 0.0032383697107434273}, {'label': 'desire', 'score': 0.0028108989354223013}, {'label': 'gratitude', 'score': 0.0023682827595621347}, {'label': 'disapproval', 'score': 0.0020829658024013042}, {'label': 'confusion', 'score': 0.00201409962028265}, {'label': 'curiosity', 'score': 0.0017185064498335123}, {'label': 'nervousness', 'score': 0.0011314954608678818}, {'label': 'sadness', 'score': 0.0010414181742817163}, {'label': 'anger', 'score': 0.0009717672946862876}, {'label': 'disappointment', 'score': 0.0009509460651315749}, {'label': 'surprise', 'score': 0.0009486081544309855}, {'label': 'fear', 'score': 0.0007174845668487251}, {'label': 'disgust', 'score': 0.00047920242650434375}, {'label': 'grief', 'score': 0.00047208095202222466}, {'label': 'embarrassment', 'score': 0.0004257410764694214}, {'label': 'remorse', 'score': 0.00026481261011213064}]])]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(df.sample(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import requests\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mood(clips_descriptions):\n",
    "    # API keys and tokens\n",
    "    API_URL_Z = \"https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta\"\n",
    "    headers_Z = {\"Authorization\": \"Bearer \"}\n",
    "\n",
    "    # Prompt tuning\n",
    "    Z_Query_Final = f\"\"\"<|system|>\n",
    "        Given the descriptions about each ten-second clips of a song, tell me what the overall mood of the song is</s>\n",
    "        <|user|>\n",
    "        {clips_descriptions}</s>\n",
    "        <|assistant|>\"\"\"\n",
    "    \n",
    "    # Generate response\n",
    "    Zephyr_B_Beta_Final_Generated_Response = requests.post(API_URL_Z, headers=headers_Z, json={\"inputs\": Z_Query_Final}).json()\n",
    "    \n",
    "    return Zephyr_B_Beta_Final_Generated_Response[0][\"generated_text\"][len(Z_Query_Final):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the descriptions provided, the overall mood of the song is groovy and could be playing in the background at a rock bar. All three clips feature a male vocalist singing melodically, with the electric guitar and bass guitar playing a prominent role in the music. The rhythmic background consists of a slow tempo beat, either from an acoustic drum or a blues acoustic drum. The use of the word \"groovy\" in each description suggests a relaxed and enjoyable atmosphere, making it suitable for a rock bar setting. Therefore, it can be concluded that the overall mood of the song is groovy and perfect for creating a laid-back ambiance in a rock bar.\n"
     ]
    }
   ],
   "source": [
    "df = dd.read_csv('DATASET/Captioned/*.csv') # this is just to get a song description\n",
    "print(get_mood(list(df[\"captioning\"])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
